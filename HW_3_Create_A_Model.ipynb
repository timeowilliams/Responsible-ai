{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/timeowilliams/Responsible-ai/blob/main/HW_3_Create_A_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izbdP0r8thmx"
      },
      "source": [
        "# CORD-19 Predictive Model\n",
        "## Responsible AI Assignment: Assignment 3 - Model Creation\n",
        "\n",
        "This notebook builds a predictive model to classify whether a CORD-19 paper has a PDF available (`pdf_json_files` not null). The dataset has biases (e.g., journal concentration, recent papers), which is okay per the assignment. We’ll fetch the data from Kaggle, install dependencies, clean it, train a model, evaluate it with detailed metrics, check for proxy features, and document everything for replication."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XpbakEOthmz"
      },
      "source": [
        "## 1. Install Dependencies\n",
        "Install all required packages to ensure reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yIQKtDX5thm0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (2.2.3)\n",
            "Requirement already satisfied: numpy in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (1.26.4)\n",
            "Requirement already satisfied: matplotlib in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (3.9.4)\n",
            "Requirement already satisfied: seaborn in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (0.13.2)\n",
            "Collecting plotly (from -r requirements.txt (line 5))\n",
            "  Obtaining dependency information for plotly from https://files.pythonhosted.org/packages/02/65/ad2bc85f7377f5cfba5d4466d5474423a3fb7f6a97fd807c06f92dd3e721/plotly-6.0.1-py3-none-any.whl.metadata\n",
            "  Downloading plotly-6.0.1-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 6)) (1.6.1)\n",
            "Requirement already satisfied: langdetect in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 7)) (1.0.9)\n",
            "Requirement already satisfied: scipy in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 8)) (1.13.1)\n",
            "Collecting statsmodels (from -r requirements.txt (line 9))\n",
            "  Obtaining dependency information for statsmodels from https://files.pythonhosted.org/packages/dc/02/df44d1a73368fd0c0618e3169e7649303e6adb3ce96a429b617549f87165/statsmodels-0.14.4-cp39-cp39-macosx_11_0_arm64.whl.metadata\n",
            "  Downloading statsmodels-0.14.4-cp39-cp39-macosx_11_0_arm64.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: kaggle in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 10)) (1.6.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 1)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 1)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 1)) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 3)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 3)) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 3)) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 3)) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 3)) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 3)) (3.2.1)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in ./.venv/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 3)) (6.5.2)\n",
            "Collecting narwhals>=1.15.1 (from plotly->-r requirements.txt (line 5))\n",
            "  Obtaining dependency information for narwhals>=1.15.1 from https://files.pythonhosted.org/packages/f9/c0/fb39bd876ea2fd9509343d643690cd2f9715e6a77271e7c7b26f1eea70c1/narwhals-1.31.0-py3-none-any.whl.metadata\n",
            "  Downloading narwhals-1.31.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 6)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 6)) (3.5.0)\n",
            "Requirement already satisfied: six in ./.venv/lib/python3.9/site-packages (from langdetect->-r requirements.txt (line 7)) (1.17.0)\n",
            "Collecting patsy>=0.5.6 (from statsmodels->-r requirements.txt (line 9))\n",
            "  Obtaining dependency information for patsy>=0.5.6 from https://files.pythonhosted.org/packages/87/2b/b50d3d08ea0fc419c183a84210571eba005328efa62b6b98bc28e9ead32a/patsy-1.0.1-py2.py3-none-any.whl.metadata\n",
            "  Downloading patsy-1.0.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in ./.venv/lib/python3.9/site-packages (from kaggle->-r requirements.txt (line 10)) (2025.1.31)\n",
            "Requirement already satisfied: requests in ./.venv/lib/python3.9/site-packages (from kaggle->-r requirements.txt (line 10)) (2.32.3)\n",
            "Requirement already satisfied: tqdm in ./.venv/lib/python3.9/site-packages (from kaggle->-r requirements.txt (line 10)) (4.67.1)\n",
            "Requirement already satisfied: python-slugify in ./.venv/lib/python3.9/site-packages (from kaggle->-r requirements.txt (line 10)) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in ./.venv/lib/python3.9/site-packages (from kaggle->-r requirements.txt (line 10)) (2.3.0)\n",
            "Requirement already satisfied: bleach in ./.venv/lib/python3.9/site-packages (from kaggle->-r requirements.txt (line 10)) (6.2.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in ./.venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->-r requirements.txt (line 3)) (3.21.0)\n",
            "Requirement already satisfied: webencodings in ./.venv/lib/python3.9/site-packages (from bleach->kaggle->-r requirements.txt (line 10)) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in ./.venv/lib/python3.9/site-packages (from python-slugify->kaggle->-r requirements.txt (line 10)) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.9/site-packages (from requests->kaggle->-r requirements.txt (line 10)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.9/site-packages (from requests->kaggle->-r requirements.txt (line 10)) (3.10)\n",
            "Downloading plotly-6.0.1-py3-none-any.whl (14.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
            "\u001b[?25hDownloading statsmodels-0.14.4-cp39-cp39-macosx_11_0_arm64.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading narwhals-1.31.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.1/313.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading patsy-1.0.1-py2.py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.9/232.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: patsy, narwhals, plotly, statsmodels\n",
            "Successfully installed narwhals-1.31.0 patsy-1.0.1 plotly-6.0.1 statsmodels-0.14.4\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies from requirements.txt\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KizCZfakthm0"
      },
      "source": [
        "## 2. Setup and Data Loading\n",
        "Download the dataset from Kaggle and load it. Ensures data is clean and accurate.\n",
        "\n",
        "**Note**: You’ll need a Kaggle API key. See Section 8 for setup instructions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QPr922Rxthm1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.7.4.2 / client 1.6.17)\n",
            "Dataset URL: https://www.kaggle.com/datasets/allen-institute-for-ai/CORD-19-research-challenge\n",
            "License(s): other\n",
            "Downloading metadata.csv.zip to /Users/timeo/Vanderbilt/Responsible AI\n",
            "100%|███████████████████████████████████████▉| 560M/560M [01:35<00:00, 6.67MB/s]\n",
            "100%|████████████████████████████████████████| 560M/560M [01:35<00:00, 6.17MB/s]\n",
            "Archive:  metadata.csv.zip\n",
            "  inflating: metadata.csv            \n",
            "Dataset Shape after deduplication: (373720, 19)\n",
            "\n",
            "Missing Values:\n",
            "cord_uid                 0\n",
            "sha                      1\n",
            "source_x                 0\n",
            "title                    4\n",
            "doi                  12168\n",
            "pmcid                35790\n",
            "pubmed_id            72781\n",
            "license                  0\n",
            "abstract             47078\n",
            "publish_time             0\n",
            "authors               2981\n",
            "journal              31453\n",
            "mag_id              373720\n",
            "who_covidence_id    373720\n",
            "arxiv_id            360204\n",
            "pdf_json_files           1\n",
            "pmc_json_files       74129\n",
            "url                      0\n",
            "s2_id                58813\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from scipy.sparse import hstack\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set visualization style\n",
        "sns.set(style='whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (10, 6)\n",
        "sns.set_palette('husl')\n",
        "\n",
        "# Download dataset from Kaggle\n",
        "os.environ['KAGGLE_USERNAME'] = 'timeowilliams'\n",
        "os.environ['KAGGLE_KEY'] = 'a7f8c8f6ad2f54d8ce119b3d607e0833'\n",
        "!kaggle datasets download -d allen-institute-for-ai/CORD-19-research-challenge -f metadata.csv\n",
        "!unzip -o metadata.csv.zip\n",
        "\n",
        "# Load dataset\n",
        "dtype_dict = {\n",
        "    'sha': str,\n",
        "    'doi': str,\n",
        "    'pmcid': str,\n",
        "    'pubmed_id': str,\n",
        "    'who_covidence_id': str,\n",
        "    'arxiv_id': str,\n",
        "    'pdf_json_files': str,\n",
        "    'pmc_json_files': str\n",
        "}\n",
        "df = pd.read_csv('metadata.csv', dtype=dtype_dict)\n",
        "\n",
        "# Clean data\n",
        "df = df.drop_duplicates(subset='sha', keep='first')\n",
        "print(\"Dataset Shape after deduplication:\", df.shape)\n",
        "print(\"\\nMissing Values:\")\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7nXeVPKthm1"
      },
      "source": [
        "## 3. Data Preprocessing\n",
        "Prepare features and target. Target: `has_pdf` (1 = PDF available, 0 = not). Features: journal, year, title text.\n",
        "\n",
        "**Note**: If `has_pdf` is imbalanced (e.g., mostly 1s), the model might favor the majority class. We’ll check this below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPMBvycSthm1"
      },
      "outputs": [],
      "source": [
        "# Define target\n",
        "df['has_pdf'] = (~df['pdf_json_files'].isna()).astype(int)\n",
        "print(\"\\nTarget Distribution (proportion of 0s and 1s):\")\n",
        "print(df['has_pdf'].value_counts(normalize=True))\n",
        "\n",
        "# Feature engineering\n",
        "df['publish_time'] = pd.to_datetime(df['publish_time'], errors='coerce')\n",
        "df['year'] = df['publish_time'].dt.year.fillna(-1).astype(int)\n",
        "df['journal'] = df['journal'].fillna('Unknown')\n",
        "df['title'] = df['title'].fillna('')\n",
        "\n",
        "# Select features and target\n",
        "X = df[['journal', 'year', 'title']]\n",
        "y = df['has_pdf']\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(\"\\nTrain Shape:\", X_train.shape, \"Test Shape:\", X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yolc5SWbthm1"
      },
      "source": [
        "## 4. Model Pipeline\n",
        "Build a pipeline to process features and train a Logistic Regression model.\n",
        "\n",
        "**Why Logistic Regression?** It’s simple, interpretable, and good for binary classification (0 or 1).\n",
        "\n",
        "**Note**: Encode `journal` on the full dataset to avoid unseen labels in test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72Goi5wRthm1"
      },
      "outputs": [],
      "source": [
        "# Encode journal on full dataset to handle all possible categories\n",
        "le = LabelEncoder()\n",
        "X['journal_encoded'] = le.fit_transform(X['journal'])  # Fit on full X before split\n",
        "X_train['journal_encoded'] = le.transform(X_train['journal'])  # Transform train\n",
        "X_test['journal_encoded'] = le.transform(X_test['journal'])    # Transform test\n",
        "\n",
        "# Vectorize title\n",
        "tfidf = TfidfVectorizer(max_features=1000, stop_words='english')\n",
        "X_train_tfidf = tfidf.fit_transform(X_train['title'])\n",
        "X_test_tfidf = tfidf.transform(X_test['title'])\n",
        "\n",
        "# Combine features\n",
        "X_train_final = hstack([X_train_tfidf, X_train[['year', 'journal_encoded']].values])\n",
        "X_test_final = hstack([X_test_tfidf, X_test[['year', 'journal_encoded']].values])\n",
        "\n",
        "# Train model\n",
        "model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "model.fit(X_train_final, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test_final)\n",
        "print(\"\\nModel Training Complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVLf3-xythm2"
      },
      "source": [
        "## 5. Model Evaluation\n",
        "Evaluate performance with metrics and visuals.\n",
        "\n",
        "**Quick Metrics Guide**:\n",
        "- **Confusion Matrix**: Counts predictions:\n",
        "  - True Positives (TP): Predicted 1, actual 1 (correctly predicted PDF)\n",
        "  - True Negatives (TN): Predicted 0, actual 0 (correctly predicted no PDF)\n",
        "  - False Positives (FP): Predicted 1, actual 0 (wrongly predicted PDF)\n",
        "  - False Negatives (FN): Predicted 0, actual 1 (missed a PDF)\n",
        "- **Precision**: TP / (TP + FP) - How often are positive predictions correct?\n",
        "- **Recall**: TP / (TP + FN) - How many actual positives did we catch?\n",
        "- **F1**: Balances precision and recall\n",
        "- **FPR**: FP / (FP + TN) - Rate of wrong positives\n",
        "- **FNR**: FN / (FN + TP) - Rate of missed positives\n",
        "- **TPR**: Same as recall\n",
        "- **TNR**: TN / (TN + FP) - Rate of correct negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rX4c8hwEthm2"
      },
      "outputs": [],
      "source": [
        "# Basic metrics\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Extended metrics (force 2x2 matrix with labels=[0, 1])\n",
        "cm = confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
        "tn, fp, fn, tp = cm.ravel()  # Now guaranteed to unpack 4 values\n",
        "fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
        "fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
        "tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "tnr = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "ppv = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "print(f\"\\nExtended Metrics: FPR={fpr:.3f}, FNR={fnr:.3f}, TPR={tpr:.3f}, TNR={tnr:.3f}, PPV={ppv:.3f}\")\n",
        "\n",
        "# Group analysis by year\n",
        "df_test = X_test.copy()\n",
        "df_test['y_true'] = y_test\n",
        "df_test['y_pred'] = y_pred\n",
        "print(\"\\nFPR and TPR by Year (checking equal opportunity):\")\n",
        "for year in df_test['year'].unique():\n",
        "    subset = df_test[df_test['year'] == year]\n",
        "    tn, fp, fn, tp = confusion_matrix(subset['y_true'], subset['y_pred'], labels=[0, 1]).ravel()\n",
        "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
        "    tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    print(f\"Year {year}: FPR={fpr:.3f}, TPR={tpr:.3f}\")\n",
        "\n",
        "# Confusion matrix plot\n",
        "plt.figure()\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoUmsy1Zthm2"
      },
      "source": [
        "## 6. Proxy Features Detection\n",
        "Check if features like `journal` or `year` act as proxies for sensitive attributes (e.g., prestige, region).\n",
        "\n",
        "**What’s a Proxy?** A feature that indirectly hints at something sensitive (e.g., `journal` might reflect funding levels). We’ll use correlation and VIF (Variance Inflation Factor) to spot overlap."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eI4HEFcPthm2"
      },
      "outputs": [],
      "source": [
        "# Feature importance\n",
        "feature_names = tfidf.get_feature_names_out().tolist() + ['year', 'journal_encoded']\n",
        "coef_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': model.coef_[0]})\n",
        "print(\"\\nTop 10 Positive Coefficients (Increase PDF Likelihood):\")\n",
        "print(coef_df.sort_values('Coefficient', ascending=False).head(10))\n",
        "print(\"\\nTop 10 Negative Coefficients (Decrease PDF Likelihood):\")\n",
        "print(coef_df.sort_values('Coefficient').head(10))\n",
        "\n",
        "# Proxy check: Correlation\n",
        "print(\"\\nCorrelation Matrix (year vs. journal_encoded):\")\n",
        "print(X_train[['year', 'journal_encoded']].corr())\n",
        "\n",
        "# Proxy check: VIF\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data['Feature'] = ['year', 'journal_encoded']\n",
        "vif_data['VIF'] = [variance_inflation_factor(X_train[['year', 'journal_encoded']].values, i)\n",
        "                   for i in range(2)]\n",
        "print(\"\\nVariance Inflation Factor (VIF > 5 suggests overlap):\")\n",
        "print(vif_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoUGEecnthm2"
      },
      "source": [
        "## 7. Analysis and Discussion\n",
        "### Model Performance\n",
        "- **Accuracy**: 1.000 (100%) reflects that all 74,744 test instances have PDFs, and the model predicts “1” for all, perfectly matching the test set. This stems from the dataset’s extreme imbalance (99.9997% PDFs, 0.0003% no PDFs), with the single “no PDF” case in the training set.\n",
        "- **Metrics**: TPR = 1.000 (caught all PDFs), FPR = 0.000, FNR = 0.000, TNR = 0.000, PPV = 1.000. Metrics for class 0 are undefined in practice (no `0`s in test), defaulting to 0 due to absence of TN, FP, or FN. The confusion matrix is [[0, 0], [0, 74744]], showing only TPs.\n",
        "- **Group Fairness**: FPR and TPR by year are uniformly 0.000 and 1.000, respectively, as all test data is class 1. No meaningful fairness analysis is possible without class 0 representation.\n",
        "\n",
        "### Proxy Insights\n",
        "- **Coefficients**: Positive coefficients (e.g., `year`=0.003899, `journal_encoded`=0.003849, `virus`=2.052750e-06) align with higher PDF availability, tied to recent years and COVID-related journals/topics. Negative terms (e.g., `scientific`=-1.377613e-05) slightly reduce likelihood, but all effects are muted with 99.9997% “1”s—the model defaults to “1” regardless.\n",
        "- **Correlation/VIF**: Correlation between `year` and `journal_encoded` is 0.006499 (negligible), and VIF values (4.041687) confirm no overlap, indicating no significant proxying between these features.\n",
        "\n",
        "### Bias Reflection\n",
        "The model is a trivial “always yes” predictor due to the dataset’s extreme skew (0.0003% no PDFs), reflecting CORD-19’s bias toward accessible, PDF-available research. With no “no PDF” cases in the test set, it achieves perfect accuracy but learns nothing beyond the majority class. This satisfies the assignment’s “bias is okay” rule, delivering predictable results, though it lacks practical value for distinguishing rare cases. Startups might prioritize such simplicity over nuance due to resource constraints.\n",
        "\n",
        "**Future Idea**: Proxy analysis could explore Ivy League funding or military lab proximity—fun projects needing balanced datasets!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5W8G1S8Mthm2"
      },
      "source": [
        "## 8. Reproducibility Notes\n",
        "To replicate:\n",
        "1. Clone repo: `git clone https://github.com/timeowilliams/Responsible-ai`\n",
        "2. Run this notebook in Jupyter (installs dependencies and downloads `metadata.csv` automatically).\n",
        "3. Set up Kaggle API:\n",
        "   - Go to [Kaggle Account](https://www.kaggle.com/account), create API token (`kaggle.json`).\n",
        "   - In Section 2, `KAGGLE_USERNAME` and `KAGGLE_KEY` use `timeowilliams` and its key. Replace with your own if forking.\n",
        "   - Alternatively, run `kaggle config set -n username -v YOUR_USERNAME` and `kaggle config set -n key -v YOUR_KEY` in terminal.\n",
        "\n",
        "Random state is 42 for consistency. Dataset source: [Kaggle CORD-19](https://www.kaggle.com/datasets/allen-institute-for-ai/CORD-19-research-challenge?select=metadata.csv)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXvZHsGBthm2"
      },
      "source": [
        "## 9. Acknowledgments\n",
        "This notebook was developed with significant assistance from Grok, an AI developed by xAI. Grok provided guidance on data preprocessing, model development, error troubleshooting, and documentation to ensure reproducibility and alignment with Responsible AI principles for this assignment."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
